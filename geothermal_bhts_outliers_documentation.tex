\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{float}
\usepackage{breqn}
\usepackage{graphicx}
\usepackage[labelformat=empty]{caption}
\usepackage{outlines}
\author{Calvin A. Whealton (caw324@cornell.edu)}
\title{Geothermal Play Fairway Analysis Code Documentation}

\begin{document}

\maketitle
The following document provides supporting information for codes written by Calvin Whealton for the Geothermal Play Fairway Analysis grant. This is not a comprehensive list of all code written for the project. Section 1 is for bottom-hole temperature corrections, section 2 is for outlier identification, and section 3 is for reservoir ideality. 

\section*{Bottom-hole Temperature Corrections}

These scripts, code, and documents pertain to the bottom-hole temperature correction calculations.

\section*{\textsf{func\_BHT\_NY\_PA\_WV\_corr.R}}

\textbf{Description}: Script with a function to compute bottom-hole temperature corrections for NY, PA, and WV based on the region. Function accepts an R data frame and returns the data frame with two additional columns for the corrected bottom-hole temperature and the error.

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Variable} & \textbf{Description}\\
\hline
\textsf{X} 			 & R data frame with variables named\\
 & \textsf{bht\_c}: Recorded bottom-hole temperature in Celsius\\
 & \textsf{calc\_depth\_m}: Calculated depth of well in meters\\
 & \textsf{reg}:  Region for that point\\
 & 0=Rome Trough and areas south east in PA\\
 & 1=Allegheny Plateau (NY and north east PA)\\
 & 2=West VA Correction\\
 & 3=Allegheny Plateau with drilling fluid information\\
\hline
\end{tabular} 
\end{table}

The output is a data frame with the following columns added.

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Output} & \textbf{Description}\\
\hline
\textsf{corr\_bht\_c} 	 & Corrected bottom-hole temperature in Celsius \\
\textsf{corr\_error}		 & Error from calculation of correcting the bottom-hole temperature\\
  & 0: no errors\\
  & 20: depth outside of normal range\\
  & 21: depth is negative\\
  & 22: depth is missing for Allegheny Plateau or West Virginia data\\
  & 30: categorical variable not 0,1, 2, or 3\\
  & 32: categorical variable missing\\
  & 42: bottom-hole missing\\
\hline
\end{tabular} 
\end{table}

\textbf{Equations}: The equations used to calculate the temperature correction $\Delta T$ are given below. Depth ($z_0$) is in meters and temperature correction ($\Delta T$) is in Celsius. See Frone and Blackwell (2010) for details on the modified Harrison correction. If no region is specified no temperature correction is computed and an error is printed in the output.

\begin{equation} \label{DT_ap}
{\Delta T}_{Alle. Plat.} =  \left\{
\begin{array}{ll}
0.01698\left[ \left(1933^3 + z_0^3\right)^{1/3} - 1933 \right],	& (z_0 < 4000 \mathrm{m})\\
38,  & (z_0 > 4000 \mathrm{m})\\
\end{array} \right .
\end{equation}

\begin{equation} \label{DT_rt}
{\Delta T}_{Rome Tr.} = 0
\end{equation}

\begin{equation} \label{DT_wv}
{\Delta T}_{W Va.} = \min\{15, -3.562+0.00763z_0 \}
\end{equation}

\begin{equation} \label{AP_mud}
{\Delta T}_{Alle. Plat., mud} =  \left\{
\begin{array}{ll}
0.01503\left[ \left(1519^3 + z_0^3\right)^{1/3} - 1519 \right],	& (z_0 < 4000 \mathrm{m})\\
38.4,  & (z_0 > 4000 \mathrm{m})\\
\end{array} \right .
\end{equation}

\begin{equation} \label{AP_air}
{\Delta T}_{Alle. Plat., air} =  \left\{
\begin{array}{ll}
0.00564\left[ \left(240^3 + z_0^3\right)^{1/3} -240 \right],	& (z_0 < 2500 \mathrm{m})\\
12.8,  & (z_0 > 2500\mathrm{m})\\
\end{array} \right .
\end{equation}

\begin{equation} \label{AP_oth}
{\Delta T}_{Alle. Plat., other} = \mathrm{Prob}(mud) {\Delta T}_{Alle. Plat., mud} + \mathrm{Prob}(air){\Delta T}_{Alle. Plat., air}
\end{equation}


\subsection*{\textsf{example\_bht\_corr.R}}

\textbf{Description}: Script to run the function \textsf{func\_BHT\_NY\_PA\_WV\_corr.R} with synthetic data in \textsf{bht\_test\_data.csv}. The output should be corrected BHTs and cases that generate all errors for missing values or values outside typical ranges.

\subsection*{\textsf{bht\_test\_data.csv}}

\textbf{Description}: Synthetic data to test \textsf{func\_BHT\_NY\_PA\_WV\_corr.R} for proper corrections and generating all possible errors.

\newpage

\section*{Outliers}
These codes, scripts, and files pertain to the outlier identification procedures.

\subsection*{\textsf{outlier\_identification.R}}

\textbf{Description}: Script with several functions to compute outliers using one of the specified algorithms with the specified inputs. Most algorithms have separate functions described below.

\begin{table}[H]
\begin{tabular} {p{2.5cm} p{10cm}}
\hline
\textbf{Function} & \textbf{Description}\\
\hline
\textsf{outlier\_iden} & General function to call other functions and perform outlier identification \\
\textsf{outlier\_loc\_pts} & Local outlier identification for \textsf{algo}=1\\
\textsf{outlier\_loc\_rad} & Local outlier identification for \textsf{algo}=2\\
\textsf{outlier\_loc\_grid} & Local outlier identification for \textsf{algo}=3\\
\textsf{outlier\_glob} & Global outlier identification\\
\hline
\end{tabular} 
\end{table}

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Variable} & \textbf{Description}\\
\hline
\textsf{X} 			 & R data frame with variables named \\
 & \textsf{x\_coord}: Longitude coordinate in km\\
 & \textsf{y\_coord}: Latitude coordinate in km\\
 & \textsf{test}: Variable to be tested for being an outlier\\
\textsf{algo} & algorithm for determining local outlier\\
 & 1: (Default) Finds nearest points\\
 & 2: Finding all points within a given radius\\
 & 3: Gridding data\\
\textsf{outcri} & Outlier criteria\\
 & 1: (Default) Only local outliers flagged as outliers\\
 & 2: Only local and global outliers flagged as outliers\\
 & 3: Only global outliers flagged as outliers\\
\textsf{pt\_eval} & Number of points used in when \textsf{algo}=1 (default = 25)\\
\textsf{rad\_eval} & Radius (in km) at which to take points when \textsf{algo}=2 (default = 16)\\
\textsf{box\_size} & Size of spacing (in km) to form grids when \textsf{algo}=3 (default = 32)\\
\textsf{pt\_min} & Minimum number of points required to perform local test for \textsf{algo}=2 or 3 (default = 25)\\
\textsf{rad\_max} & Maximum radius (in km) at which to take points when \textsf{algo}=1 (default = 16)\\
\textsf{k\_glob} & Constant multiplied by the upper- and lower-half quartile ranges in global analysis (default = 3)\\
\textsf{k\_loc} & Constant multiplied by the upper- and lower-half quartile ranges in local analysis (default = 3)\\
\textsf{type}	 & Type of quantile estimation (default = 7, see R documentation)\\
\hline
\end{tabular} 
\end{table}

The output is a data frame with the following columns added. The local outlier columns will only be added when \textsf{outcri}=1 or 2. The global outlier columns will only be added when \textsf{outcri}=2 or 3. The \textsf{outs} column will be present in all output.

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Output} & \textbf{Description}\\
\hline
\textsf{outs}	 & Binary variable for points being an outlier (1=outlier)\\
\hline
\textsf{out\_loc\_lo} & Binary variable for point being a local low outlier (1=outlier)) \\
\textsf{out\_loc\_hi} & Binary variable for point being a local high outlier (1=outlier) \\
\textsf{out\_loc\_lq} & Lower quartile for local outlier test (NA if not tested) \\
\textsf{out\_loc\_mq} & Median for local outlier test (NA if not tested) \\
\textsf{out\_loc\_uq} & Upper for local outlier test (NA if not tested) \\
\textsf{out\_loc\_lb} & Lower bound for local outlier test (NA if not tested)\\
\textsf{out\_loc\_ub} & Upper bound for local outlier test (NA if not tested)\\
\textsf{out\_loc\_rad} & Maximum distance to point (only for algo=1)\\
\textsf{out\_loc\_pts} & Number of points in local area (only for algo=2 and 3)\\
\textsf{out\_loc\_error} & Error in local outlier calculation\\
 & 0: No errors\\
 & 1: Some points outside \textsf{rad\_max} when \textsf{algo}=1)\\
 & 2: Fewer than \textsf{pt\_min} points in region when \textsf{algo}=2 or 3)\\
\hline
\textsf{out\_glob\_lo} &  Binary variable for points being an global low outlier (1=outlier)\\
\textsf{out\_glob\_hi} &  Binary variable for points being an global high outlier (1=outlier)\\
\hline
\end{tabular} 
\end{table}

\textbf{Equations}: The equations used to calculate low and high outlier bounds are given below. In these equations $q$ is a variable of interest (\textsf{test} in the data) with subscripts denoting quantiles and $k$ is the constant (\textsf{k\_loc} or \textsf{k\_glob}). The equations can be applied locally or globally. Aguirre (2014) uses an outlier test that is similar, but the version implemented in this code is more flexible.

\begin{equation} \label{lb}
B_{lower} = q_{0.25} - k(q_{0.5} - q_{0.25})
\end{equation}

\begin{equation} \label{ub}
B_{upper} = q_{0.75} + k(q_{0.75} - q_{0.5})
\end{equation}

\subsection*{\textsf{example\_outlier\_code.R}}

\textbf{Description}: Script to run outlier identification functions with test data and the Cornell dataset. Later portions do not need to be run because they were testing sensitivity of the algorithm to the input parameters. They are kept in the code for potential future analysis.

\subsection*{\textsf{out\_test\_grid.csv}}

\textbf{Description}: Synthetic data to test the local outlier identification algorithm that uses gridding.

\subsection*{\textsf{out\_test\_rad.csv}}

\textbf{Description}: Synthetic data to test the local outlier identification algorithm that uses maximum radius.

\subsection*{\textsf{out\_test\_pt.csv}}

\textbf{Description}: Synthetic data to test the local outlier identification algorithm that uses number of points.

\subsection*{\textsf{cornell\_data.csv}}

\textbf{Description}: Cornell heat flow database with 8,919 points used to test sensitivity of the outlier identification algorithm. See Cornell University (2014).

\newpage

\section*{Reservoir Ideality}

\subsection*{\textsf{MainIdeality.m}}

\textbf{Description}: Script that runs the reservoir ideality uncertainty analysis. Subsidiary functions are called from this script. This script also imports an example dataset and uncertainty mapping from \textsf{TestFormationData.csv} and \textsf{TestUncertaintyLevels.csv}, respectively. This script can be modified to include more graphs and statistical analysis.

\subsection*{\textsf{GenRandNums.m}}

\textbf{Description}: Function to generate random numbers from uniform, triangular, normal, or lognormal distributions.

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Variable} & \textbf{Description}\\
\hline
\textsf{mean} 			 & Mean value of the distribution (real-space)\\
\textsf{unc} & uncertainty (spread) of the distribution as a percentage of the mean\\
 & uniform: bounds are defined from uncertainty\\
 & triangular: bounds are defined from uncertainty\\
 & normal: 95\% central region of distribution defined by uncertainty\\
 & lognormal: real-space coefficient of variation  defined by uncertainty\\
\textsf{dist} & Distribution selected\\
 & 1: Non-standard uniform distribution\\
 & 2: Triangular distribution, symmetric\\
 & 3: Normal distribution\\
 & 4: Lognormal distribution\\
\textsf{reps} & Number of replicates to generate\\
\hline
\end{tabular} 
\end{table}

The output is a column vector with of numbers for the specified distribution.

\subsection*{\textsf{MonteCarloApprox.m}}

\textbf{Description}: Function to calculate Monte Carlo Approximation of the distribution of reservoir ideality.

\begin{table}[H]
\begin{tabular} {p{2cm} p{11cm}}
\hline
\textbf{Variable} & \textbf{Description}\\
\hline
\textsf{mat} 			 & Matrix of random values for reservoir ideality calculation\\
 & column 1: $k$, permeability/conductivity\\
 & column 2: $H$, thickness\\
 & column 3: $P_o$, pressure\\
 & column 4: $P_b$, pressure\\
 & column 5: $R_o$, radius\\
\textsf{mu} & Viscosity\\
\textsf{Rb} & Casing radius\\
\textsf{ideality} & ideality metric\\
 & 1: $(2\pi/\mu)kH(P_o - P_b)/(\ln(R_b) - \ln(R_o))$\\
 & 2: not currently used\\
\textsf{reps} & Number of replicates to generate\\
\hline
\end{tabular} 
\end{table}

Note that in the code $P_{diff} = -|P_o - P_b|$ is used. The difference between $P_o$ and $P_b$ should be large so that this is generally not necessary, but it ensures that there are no problems. The output is a column vector with the distribution of the reservoir ideality.

\subsection*{\textsf{TestFormationData.csv}}

\textbf{Description}: Example file for input of formation data. The version of MATLAB used to develop this could not handle strings and numbers, so all input converted to numbers. The header line is dropped when reading-in the file.

\subsection*{\textsf{TestUncertaintyLevels.csv}}

\textbf{Description}: Example file for mapping uncertainty levels in \textsf{TestFormationData.csv} to percentage uncertainty. Column 1 is the uncertainty mapping (1-5). Columns 2-6 are the percentage uncertainty associated with that level for $k$, $H$, $P_o$, $P_b$, and $R_o$, respectively.

\newpage

\section*{References}

Aguirre, G. A. (2014). \textit{Geothermal Resource Assessment: A Case Study of Spatial Variability and Uncertainty Analysis for the States of New York and Pennsylvania}. Master's Thesis, Environmental and Water Resources Systems Engineering, School of Civil and Environmental Engineering, Cornell University.\hfill
\bigskip

\noindent
Cornell University (2014). Cornell University Heat Flow Database (NY and PA). Southern Methodist University Geothermal Laboratory. (Accessed 16 June 2014) geothermal.smu.edu/static/DownloadFilesButtonPage.htm \hfill
\bigskip

\noindent
Frone, Z. and Blackwell, D. (2010). Geothermal Map of the Northeastern United States and the West Virginia Thermal Anomaly. \textit{Geothermal Resources Council Transactions 34}:339-344.
\end{document}